# Ralph Progress Log
Started: Mon Jan 26 21:15:43 CST 2026

## Codebase Patterns
- WLC Dashboard data is stored in `~/.noc_toolkit/noc_toolkit.db` (not project-local db)
- Passwords are encrypted using Fernet cipher stored in `wlc_dashboard.key`
- Settings save/load functions use INSERT...ON CONFLICT for upsert pattern
- Database migrations use try/except around ALTER TABLE to handle existing columns
- Threading uses daemon threads with wake events for responsive polling
- Credentials are shared between Cisco and Aruba controllers
- Auto-discovery pulls from SolarWinds nodes table
- **IMPORTANT**: `security.py` uses project-local `noc_toolkit.db` for auth, while `db_jobs.py` uses `~/.noc_toolkit/noc_toolkit.db` for data
- Bulk SSH uses ThreadPoolExecutor for parallel execution (default 10 workers)
- Template variables use `{{variable_name}}` syntax, extracted via regex
- Schedule credentials are Fernet-encrypted in database
- **IMPORTANT**: Always use `_CST_TZ = ZoneInfo("America/Chicago")` for timezone-aware datetime in scheduling code
- Change statuses: scheduled, running, completed, failed, rollback-running, rolled-back, rollback-failed
- Change scheduler runs every 30 seconds; uses `_CHANGE_WAKE.set()` for immediate wake-up
- SolarWinds API uses SWIS REST endpoint on port 17778 (`/SolarWinds/InformationService/v3/Json/Query`)
- SolarWinds settings use in-memory cache (`_SOLAR_SETTINGS`) with lock, synced to DB on change
- WLC/Aruba hosts auto-detected from SolarWinds nodes via hostname/vendor/model patterns
---

## 2026-01-26 21:30 - US-001
- **What was implemented**: Audited WLC Dashboard and Polling System
- **Issues found and fixed**:
  1. **FIXED: Aruba settings not persisted to database** - `aruba_hosts` and `aruba_enabled` were defined in defaults but never saved/loaded from DB
     - Added migration to create `aruba_hosts_json` and `aruba_enabled` columns
     - Updated `load_wlc_dashboard_settings()` to read Aruba settings
     - Updated `save_wlc_dashboard_settings()` to write Aruba settings
  2. **FIXED: Duplicate code block** - Removed duplicate `poll_summary` loading (lines 931-938 had same block twice)
- **Files changed**:
  - `tools/db_jobs.py` - Added Aruba column migrations, fixed load/save functions
- **Verification**:
  - Settings page displays both Cisco 9800 (104) and Aruba 72XX (26) controllers
  - Polling interval displays correctly (5 minutes)
  - Time range buttons work (24h, 3d, 7d, 30d)
  - Stat cards render correctly (Total Clients, Access Points, Polling Status)
  - Aruba settings now persist in database (`aruba_hosts_json`, `aruba_enabled` columns verified)
- **Learnings for future iterations**:
  - Check that new settings fields have corresponding DB columns and are in load/save functions
  - Test settings persistence by restarting app
  - The password hash format must match what `verify_user()` expects (werkzeug pbkdf2)
---

## 2026-01-26 22:15 - US-002
- **What was implemented**: Audited Bulk SSH Tool and Templates
- **Issues found**: None - all functionality working correctly
- **Verification completed**:
  - Template CRUD operations work (create, read, update, delete)
  - Default templates seed correctly (10 common templates)
  - Variable substitution syntax `{{variable}}` displays correctly
  - Template categories (backup, monitoring, routing, troubleshooting) work
  - Job history page renders correctly (empty state shown)
  - Scheduled jobs page renders correctly
  - Main execution page has all required fields:
    - Device selection (paste list, from inventory)
    - Authentication (username, password, enable secret)
    - Command input with template dropdown
    - Options (Show Commands/Config Mode, Device Type, Parallel Connections, Timeout)
  - CSV export route exists and is properly implemented
  - Results storage uses `bulk_ssh_jobs` and `bulk_ssh_results` tables
- **Files changed**: None (no issues found)
- **Code review findings**:
  - BulkSSHJob class in `tools/bulk_ssh.py` uses ThreadPoolExecutor correctly
  - Template engine in `tools/template_engine.py` properly extracts and substitutes variables
  - Database layer in `tools/db_jobs.py` has proper CRUD functions with encryption
  - Schedule worker in `tools/schedule_worker.py` checks every 60 seconds for due jobs
  - Routes in `app.py` lines 5171-5608 handle all Bulk SSH operations
- **Learnings for future iterations**:
  - Bulk SSH templates are stored in `bulk_ssh_templates` table
  - Job results stored in `bulk_ssh_jobs` (metadata) and `bulk_ssh_results` (per-device output)
  - Schedule credentials are encrypted with Fernet before storage
  - Email alerting for schedule failures is a placeholder (not implemented)
---

## 2026-01-27 01:00 - US-003
- **What was implemented**: Audited Bulk SSH Scheduling System
- **Issues found and fixed**:
  1. **FIXED: Timezone mismatch in schedule_worker.py** - `_calculate_next_run()` used naive `datetime.now()` while schedule creation used `datetime.now(_CST_TZ)`. This caused inconsistent timezone handling.
     - Added `ZoneInfo` import and `_CST_TZ = ZoneInfo("America/Chicago")` constant
     - Updated `_calculate_next_run()` to use `datetime.now(_CST_TZ)`
     - Updated `last_run` timestamp to use `datetime.now(_CST_TZ)`
     - Fixed ISE cert sync to handle timezone-aware datetime comparisons
  2. **FIXED: Timezone mismatch in db_jobs.py** - `fetch_due_bulk_ssh_schedules()` used naive `datetime.now()`
     - Added `ZoneInfo` import and `_CST_TZ` constant
     - Updated `fetch_due_bulk_ssh_schedules()` to use `datetime.now(_CST_TZ)`
  3. **ADDED: Missing schedule creation UI** - No UI existed for creating scheduled jobs
     - Added "Create Schedule" button to page header
     - Added modal form with all required fields (name, devices, command, credentials)
     - Schedule type selector (one-time, daily, weekly) with dynamic config sections
     - Alert on failure checkbox and email field
- **Files changed**:
  - `tools/schedule_worker.py` - Timezone fixes, ZoneInfo import
  - `tools/db_jobs.py` - Timezone fix for fetch_due_bulk_ssh_schedules
  - `templates/bulk_ssh_schedules.html` - Added create modal, CSS, JavaScript
- **Verification**:
  - Schedule creation works (tested one-time schedule)
  - Schedule type switching works (one-time, daily, weekly)
  - next_run shows correct timezone offset (-06:00 for CST)
  - Enable/disable toggle works correctly
  - Schedule shows in list with all metadata (type, next_run, last_run, command)
- **Learnings for future iterations**:
  - Always use timezone-aware datetime for scheduling (use `_CST_TZ` constant)
  - Schedule types are: once, daily, weekly (NOT cron expressions)
  - Email alerting is not implemented (placeholder only)
  - Schedule worker checks every 60 seconds via daemon thread
---

## 2026-01-27 07:00 - US-004
- **What was implemented**: Audited Change Management Workflow
- **Issues found and fixed**:
  1. **FIXED: Missing CSS status classes** - `changes.html` only had styles for `pending`, `completed`, `failed`, `cancelled`, but actual statuses are: `scheduled`, `running`, `rollback-running`, `rolled-back`, `rollback-failed`
     - Added `.status-scheduled` (accent/blue color)
     - Added `.status-running` (info/blue color)
     - Added `.status-rollback-running` (warning/yellow color)
     - Added `.status-rolled-back` (success/green color)
     - Added `.status-rollback-failed` (error/red color)
- **Files changed**:
  - `templates/changes.html` - Added missing CSS status badge classes
- **Verification**:
  - Change window creation with scheduled datetime works
  - Change scheduler loop runs every 30 seconds via daemon thread
  - "Start Now" button triggers immediate execution
  - Status transitions work: scheduled → running → completed/failed
  - Rollback triggers correctly with status: → rollback-running → rolled-back/rollback-failed
  - Timeline shows all change events (created, started, completed, error, rollback-start, rollback-complete)
  - Apply Job Logs and Rollback Job Logs sections display correctly
  - Audit Log link filters correctly by change number
- **Code review findings**:
  - Change scheduler in `app.py` (`_change_scheduler_loop`) runs every 30 seconds
  - Uses `_CHANGE_WAKE` threading.Event for manual wake-up on schedule creation
  - Changes stored in `change_windows` table, events in `change_events` table
  - Credentials encrypted with Fernet before storage via `_encode_change_payload()`
  - Status transitions: scheduled → running → completed/failed, then optionally → rollback-running → rolled-back/rollback-failed
  - Changes created via `/actions/schedule` endpoint (from Interface Search or Global Config tools)
  - Also created via `/tools/wlc/summer-guest/schedule` for WLC Summer Guest automation
- **Learnings for future iterations**:
  - Change statuses: scheduled, running, completed, failed, rollback-running, rolled-back, rollback-failed
  - Scheduler uses UTC for storage, CST for display (via `_format_cst()` helper)
  - Background CLI jobs use `_start_background_cli_job()` which spawns daemon threads
  - Job completion signals `_CHANGE_WAKE.set()` to wake scheduler immediately
---

## 2026-01-27 08:30 - US-005
- **What was implemented**: Audited SolarWinds Integration
- **Issues found**: None - all functionality working correctly
- **Verification completed**:
  - Settings page at `/tools/solarwinds/nodes/settings`:
    - Base URL saves correctly (using SWIS API port 17774)
    - Username persists correctly (supports domain\user format)
    - Password encrypts with Fernet before storage, shown as masked placeholder on reload
    - SSL verification checkbox works correctly
    - "Save Settings" and "Save & Poll" buttons function correctly
  - Connection/poll validation:
    - Auto-port upgrade to SWIS port 17778 works for standard HTTPS
    - API endpoint discovery tries multiple paths (/SolarWinds/InformationService, /Orion/InformationService, etc.)
    - Error messages are descriptive (connection failed, 404, invalid JSON)
  - Node sync verified (17028 nodes fetched):
    - All expected fields populated: node_id, caption, organization, vendor, model, version, ip_address, status, last_seen
    - Organization mapping via CustomProperties.Organization query
    - Vendor auto-detection from MachineType or caption when not provided
    - Extra JSON stored for raw node data
  - Nodes display page at `/tools/solarwinds/nodes`:
    - All fields render correctly in table
    - Client-side filtering works (tested filtering by vendor "cisco" - 9105 matches)
    - Pagination works (100 rows per page)
    - Last poll timestamp and status displayed
    - Links to settings and changes pages
  - Integration points verified:
    - WLC hosts auto-derived from SolarWinds nodes (hostname contains "wc01", vendor "cisco", model "9800")
    - Aruba hosts auto-derived (hostname starts with "wc0", vendor starts with "aruba")
    - Summer guest hosts sync from same WLC detection
    - API endpoint `/api/solarwinds/nodes` returns filtered nodes for bulk SSH inventory search
- **Files changed**: None (no issues found)
- **Code review findings**:
  - SolarWinds API client in `tools/solarwinds.py` with robust endpoint discovery
  - Database functions in `tools/db_jobs.py` lines 1412-1561
  - Settings use in-memory cache with lock (`_SOLAR_SETTINGS_LOCK`) plus DB persistence
  - Poll timestamp uses CST timezone (`datetime.now(_CST_TZ)`)
  - Routes require superadmin for settings, login for viewing nodes
- **Learnings for future iterations**:
  - SolarWinds settings cached in `_SOLAR_SETTINGS` dict with lock protection
  - API uses SWIS (SolarWinds Information Service) REST API on port 17778
  - Organization comes from CustomProperties.Organization in Orion
  - Node sync replaces all nodes (DELETE then INSERT pattern)
  - WLC/Aruba host detection uses specific naming patterns from organization
- Summer Guest scheduler uses `_SUMMER_WAKE` threading.Event for immediate wake-up and waits up to 5 minutes between checks
---

## 2026-01-27 10:15 - US-006
- **What was implemented**: Audited WLC Summer Guest Automation
- **Issues found**: None - all functionality working correctly
- **Verification completed**:
  - Settings page at `/tools/wlc/summer-guest/settings`:
    - Username, password, enable secret save correctly
    - Password encrypted with Fernet before storage
    - Profile names and WLAN IDs persist correctly
    - Poll time (HH:MM format) saves correctly (tested 08:30)
    - Timezone saves correctly (tested America/New_York)
    - Enable scheduler checkbox persists correctly
    - Validation results section displays connection test results
    - "Run Now", "Save & Run", "Save Settings" buttons all work
  - Monitor page at `/tools/wlc/summer-guest`:
    - Status pill shows correct state (Never/OK/Partial/Error)
    - Last poll and next poll timestamps display correctly
    - Next poll shows in configured timezone with proper offset (e.g., "2026-01-28 08:30 AM EST")
    - Targets section shows profile names, WLAN IDs, and auto prefix match
    - Controller filter works for searching host cards
    - Controller cards show hostname, status, and WLAN entries
    - Enable/Disable action popover for immediate toggle
    - Schedule CHG action popover for creating change windows
    - Recent Polls expandable section shows poll history
  - Scheduling integration:
    - Changes created via `/tools/wlc/summer-guest/schedule` endpoint
    - Uses change_windows table for scheduling enable/disable
    - Supports auto-rollback option
    - Change events logged: scheduled, started, completed, error
    - Upcoming changes shown as "Scheduled CHG" badge on controller cards
  - Audit logging verified:
    - WLAN toggle actions logged as `wlc_wlan_toggle` to audit trail
    - WLAN schedule actions logged as `wlc_wlan_schedule` to audit trail
    - Change execution logged via `wlc-summer-toggle` tool in changes.csv
  - Timezone-aware scheduling:
    - `_summer_timezone()` returns ZoneInfo from configurable timezone
    - `_next_summer_run()` calculates next poll in configured timezone
    - `_summer_worker_loop()` uses configured timezone for scheduling
    - Poll timestamps stored and displayed in CST format
- **Files changed**: None (no issues found)
- **Code review findings**:
  - Summer Guest scheduler in `app.py` (`_summer_worker_loop`) uses daemon thread
  - Settings stored in `wlc_summer_settings` table with JSON columns for lists
  - Poll samples stored in `wlc_summer_samples` table with cleanup after 30 days
  - WLC hosts auto-populated from SolarWinds (hostname contains "wc01", vendor "Cisco", model "9800")
  - WLAN state changes via `set_wlan_state()` in `tools/wlc_summer_guest.py`
  - Uses netmiko IOS-XE connection for CLI commands
- **Learnings for future iterations**:
  - Summer Guest has its own configurable timezone (separate from other schedulers)
  - `_SUMMER_WAKE.set()` triggers immediate poll when settings change
  - Scheduler waits up to 5 minutes (300s) between checks when no poll is due
  - Auto prefix match "Summer*" catches all profiles starting with "Summer"
  - WLAN toggle uses: `wlan <profile_name> <wlan_id>`, `no shutdown`/`shutdown`, `write memory`
---
